{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tổng hợp số liệu báo cáo giám định hàng tháng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [] # Biến chứa các dữ liệu file Excel sau khi tải vào dataframe\n",
    "file_list = glob.glob(r'C:\\Users\\PC\\Desktop\\TESST\\*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in file_list:\n",
    "    df = pd.concat(pd.read_excel(filename, sheet_name=None  ,dtype=str), ignore_index=True)\n",
    "    files.append(df)\n",
    "frame = pd.concat(files, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "result = frame\n",
    "index_colunms = [0,1,2,3,4,14,15,16,17,18,19]\n",
    "result = result.iloc[:,index_colunms] \n",
    "df_edit = result.dropna(how='all')\n",
    "df_edit = df_edit.copy()\n",
    "df_edit.columns = ['STT', 'HOTEN', 'MASOBHXH', 'NGAYSINH','LUONG','TUNGAY','DENNGAY','TYLE','MADONVI','GHICHU','NGAYTAO']\n",
    "df_edit.dropna(subset=['STT'], inplace=True)\n",
    "index_2 = df_edit[df_edit['STT'].str.contains('BI[A-Za-z0-9]{4}[A-Za-z]')]\n",
    "\n",
    "for i in index_2.index:  \n",
    "    value = str(index_2.at[i, 'STT'])\n",
    "    k = re.findall(r'BI[A-Za-z0-9]{4}[A-Za-z]', value)     \n",
    "    mask  = df_edit.index > i\n",
    "    df_edit.loc[mask, 'MADONVI'] = k\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edit.to_excel(r'C:\\Users\\PC\\Desktop\\TESST\\GOMFILE.xlsx',index = False ) # xuất dữ liệu ra tập tin Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49c78076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07648/2023/09201\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "while True:\n",
    "    files = os.listdir(r'D:\\TTT')\n",
    "    files = [f for f in files if not f.startswith('.')]\n",
    "    files.sort(key=lambda f: os.path.getmtime(os.path.join('D:\\TTT', f)), reverse=True)\n",
    "    if files and files[0].endswith('.xlsx'):\n",
    "        file_path = os.path.join('D:\\TTT', files[0])\n",
    "        break\n",
    "    time.sleep(1)\n",
    "df = pd.read_excel(file_path)\n",
    "#print(df)\n",
    "sum_columns = df['ML'] * df['SOTHANG'] * ( df['TYLE'] / 100)\n",
    "df['CHIPHINOP'] = sum_columns\n",
    "pattern = r\"\\d{5}/\\d{4}/\\d{5}\"\n",
    "# str[0] do findall trả về giá trị là mảng nên lấy giá trị đầu tiên khi tìm thấy\n",
    "df[\"MA_HO_SO\"] = df['GHICHU'].str.findall(pattern).str[0]\n",
    "grouped_df = df.groupby(['MA_HO_SO'])['CHIPHINOP'].sum().reset_index()\n",
    "for index, row in grouped_df.iterrows():\n",
    "    MA_HO_SO = grouped_df.loc[index,\"MA_HO_SO\"]\n",
    "    print(MA_HO_SO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e124efeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/03/2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "# create a starting date\n",
    "start_date = date.today()\n",
    "#print(start_date)\n",
    "# add 7 business days\n",
    "offset = pd.offsets.BDay(7)\n",
    "end_date = (start_date + offset)\n",
    "\n",
    "print(end_date.strftime('%d/%m/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bb1d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'D:\\Download'\n",
    "file_list = os.listdir(folder_path)\n",
    "files = []\n",
    "for filename in file_list:    \n",
    "    if filename.endswith('.xlsx'):         \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        time.sleep(1)\n",
    "        df = pd.read_excel(file_path, sheet_name = 0)\n",
    "        df['DON_VI'] =  filename[:7]\n",
    "        df['TRANG_THAI'] = 1\n",
    "        df['TONG_TIEN_NOP'] = 0  \n",
    "        df['NGAY_TAO'] = dt.datetime.today().strftime(\"%Y%m%d\")        \n",
    "        #print(df)\n",
    "        files.append(df)\n",
    "\n",
    "crawl_data = pd.concat(files, axis=0, ignore_index = True)\n",
    "tong_chi_phi_nop = crawl_data['ML'] * crawl_data['SOTHANG'] * ( crawl_data['TYLE'] / 100)\n",
    "crawl_data['TONG_TIEN_NOP'] = tong_chi_phi_nop\n",
    "pattern = r\"\\d{5}/\\d{4}/\\d{3,5}\"\n",
    "crawl_data[\"MA_HO_SO\"] = crawl_data['GHICHU'].str.findall(pattern).str[0]\n",
    "column_mapping = {'MA_HO_SO': 'MA_HO_SO', 'SOBHXH': 'MASO_BHXH', 'HOTEN': 'HO_TEN' , 'ML' : 'MUC_LUONG', 'SOTHANG' : 'SO_THANG' , 'TYLE' : 'TY_LE', 'TONG_TIEN_NOP' : 'TONG_TIEN_NOP'  , 'DON_VI' : 'DON_VI', 'TRANG_THAI' : 'TRANG_THAI' , 'SOBL' : 'SO_BIEN_LAI' ,'NGAYBL' : 'NGAY_BIEN_LAI' } \n",
    "crawl_data = crawl_data.rename(columns=column_mapping)\n",
    "deltails_value_out = crawl_data[[\"MA_HO_SO\",\"MASO_BHXH\",\"HO_TEN\",\"MUC_LUONG\",\"SO_THANG\",\"TY_LE\", \"TONG_TIEN_NOP\" ,\"SO_BIEN_LAI\",\"NGAY_BIEN_LAI\",\"DON_VI\", \"TRANG_THAI\"]].copy()\n",
    "db_path = r\"E:\\DOCUMENT_DB.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "deltails_value_out.to_sql('HO_SO_TNHS', conn, if_exists='append', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8dd3cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "\n",
    "# get the value in the first row of the 'B' column\n",
    "value = df.iloc[0]['A']\n",
    "\n",
    "print(value)  # output: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "Result = pd.DataFrame({'SO_HS': ['07648/2023/09201'], 'THOI_GIAN_NHAN': ['11/11/2023 15:30'] })\n",
    "# Tạo mới nếu folder không tồn tại \n",
    "LINK_DOWNLOAD_FOLDER = r\"D:\\TT_App_Download\"                      \n",
    "file_list = os.listdir(LINK_DOWNLOAD_FOLDER) \n",
    "files = []\n",
    "for filename in file_list: \n",
    "    \n",
    "    if filename.endswith('.xlsx'):         \n",
    "        file_path = os.path.join(LINK_DOWNLOAD_FOLDER, filename)                               \n",
    "        df = pd.read_excel(file_path, sheet_name = 0) \n",
    "        pattern = r\"\\d{5}/\\d{4}/\\d{3,5}\"\n",
    "        df['MA_HO_SO'] = df['GHICHU'].str.findall(pattern).str[0]      \n",
    "        df['DON_VI'] =  filename[:7]\n",
    "        df['TRANG_THAI'] = 1\n",
    "        tong_chi_phi_nop = df['ML'] * df['SOTHANG'] * ( df['TYLE'] / 100)\n",
    "        df['TONG_TIEN_NOP'] = tong_chi_phi_nop\n",
    "        for index,row_result_download in Result.iterrows():                                    \n",
    "            if row_result_download['SO_HS'] == df.iloc[0]['MA_HO_SO']:                                        \n",
    "                df['NGAY_NHAN'] = row_result_download['THOI_GIAN_NHAN']  \n",
    "                break                                                  \n",
    "        files.append(df)\n",
    "    crawl_data = pd.concat(files, axis=0, ignore_index = True)   \n",
    "crawl_data                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "input_string = ''\n",
    "folder_path = r'C:\\Users\\taitt.haugiang.VSS\\Desktop\\pdf'\n",
    "# Open the PDF file in read-binary mode\n",
    "for pdf_file_path in glob.glob(os.path.join(folder_path, \"*.pdf\")):\n",
    "    with open(pdf_file_path, 'rb') as pdf_file:\n",
    "        # Set up the PDFResourceManager\n",
    "        resource_manager = PDFResourceManager()\n",
    "        # Set up a StringIO object to receive the output from the TextConverter\n",
    "        output_string = StringIO()\n",
    "        # Set up the TextConverter with the output StringIO and the PDFResourceManager\n",
    "        converter = TextConverter(resource_manager, output_string, laparams=LAParams())\n",
    "        # Set up the PDFPageInterpreter with the PDFResourceManager and TextConverter\n",
    "        page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "        # Loop through each page of the PDF file and extract the text\n",
    "        for page in PDFPage.get_pages(pdf_file):\n",
    "            page_interpreter.process_page(page)\n",
    "            # Get the text from the StringIO object\n",
    "            text = output_string.getvalue()\n",
    "            # Split the text into lines\n",
    "            lines = text.split(\"\\n\")\n",
    "            # Loop through each line and check if it contains the keyword \"Đợt\"\n",
    "            for line in lines:\n",
    "                if \"Đợt\" in line:\n",
    "                    input_string = line\n",
    "            # Reset the StringIO object for the next page\n",
    "            output_string.seek(0)\n",
    "            output_string.truncate()\n",
    "        # Close the StringIO and TextConverter objects\n",
    "        pattern = r'\\d+\\.?\\d*'\n",
    "        matches = re.findall(pattern, input_string)\n",
    "        # Print the extracted numerical values\n",
    "        final = ''.join(matches)   \n",
    "              \n",
    "        output_string.close()\n",
    "        converter.close()\n",
    "\n",
    "pdf_file_name = os.path.basename(pdf_file_path)\n",
    "new_pdf_file_path = os.path.join(folder_path, final + \".pdf\")\n",
    "os.rename(pdf_file_path, new_pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170e5677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file\n",
      "xxx\n"
     ]
    }
   ],
   "source": [
    "filename = \"file_xxx\"\n",
    "file, xxx = filename.split(\"_\")\n",
    "print(file) # prints \"file\"\n",
    "print(xxx) # prints \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9fb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "deltails_value_out = pd.DataFrame({'MA_HO_SO': ['04483/2023/093', '04483/2023/093'], 'MASO_BHXH': ['9320866922', '9320866923'] , 'HO_TEN': ['A', 'B'] , 'MUC_LUONG': [1, 1] , 'SO_THANG': [1, 1] , 'TY_LE': [1, 1] , 'TONG_TIEN_NOP': [1, 1] , 'SO_BIEN_LAI': [1, 1]  , 'DON_VI': ['BI0034A', 'BI0034A'] , 'TRANG_THAI': [1, 1] ,'LOG': [1, 1] , 'NGAY_BIEN_LAI': [1, 1]  ,'NGAY_NHAN': [1, 1] ,'MA_QT': [1, 1] })\n",
    "#deltails_value_out\n",
    "db_path = r\"E:\\Project\\TT_Application\\DB\\DOCUMENT_DB.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "deltails_value_out.to_sql('HO_SO_TNHS', conn, if_exists='append', index=False)\n",
    "conn.execute('DELETE FROM HO_SO_TNHS WHERE rowid NOT IN (SELECT MIN(rowid) FROM HO_SO_TNHS GROUP BY MA_HO_SO, MASO_BHXH)')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1a376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x22207706ab0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "db_path = r\"E:\\Project\\TT_Application\\DB\\DOCUMENT_DB.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cur = conn.cursor()    \n",
    "values = \"BI0034A\".split(',')\n",
    "        # Join the list into a string with single quotes around each value\n",
    "values_str = ','.join([f\"'{x.strip()}'\" for x in values])\n",
    "\n",
    "cur.execute(f\"select MA_HO_SO,MA_QT,DON_VI,SUBSTR(NGAY_NHAN,1,10) as 'NGAY_NHAN',count(MASO_BHXH) as 'SO_LUOT',sum(TONG_TIEN_NOP) as 'TONG_TIEN_NOP', LOG FROM HO_SO_TNHS  WHERE TRANG_THAI = 1 AND SUBSTR(NGAY_NHAN,1,10) = '21/04/2023' AND DON_VI IN ({values_str}) GROUP BY MA_HO_SO,DON_VI,SUBSTR(NGAY_NHAN,1,10),MA_QT,LOG\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d99f6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "a = 'b'\n",
    "a = a.upper()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d91b389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28/04/2023'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_datetime = datetime.now().strftime(\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75440528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xử lý chuyển đổi dữ liệu trong danh sách từ một danh sách khác.\n",
    "import pandas as pd\n",
    "import glob\n",
    "files = [] # Biến chứa các dữ liệu file Excel sau khi tải vào dataframe\n",
    "file_list = glob.glob(r'C:\\Users\\PC\\Desktop\\C7\\*.xlsx')\n",
    "for filename in file_list:\n",
    "    df = pd.concat(pd.read_excel(filename, sheet_name=None  ,dtype=str), ignore_index=True)\n",
    "    files.append(df)\n",
    "frame = pd.concat(files, axis=0, ignore_index=True)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8893ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Nhóm đổi mã loại khám, chữa bệnh -----------------------------\n",
    "folder_excel = r\"C:\\Users\\PC\\Desktop\\DOI\"\n",
    "# Tên file excel cần xử lý\n",
    "FileName_Excel = \"DOI_MA_LOAI_KCB.xlsx\"\n",
    "result = pd.read_excel(folder_excel + \"\\\\\" + FileName_Excel)\n",
    "result\n",
    "# Thay đổi dữ liệu danh sách từ 1 danh sách khác cho trước.\n",
    "\n",
    "value_map = result.set_index('KEY')['MA_LOAI_DOI'].to_dict()\n",
    "print(\"Số lượt chuyển mã loại KCB : \" + str(result.shape[0]))\n",
    "frame['MA_LOAI_KCB_CN'] = frame['KEY'].map(value_map).fillna(frame['MA_LOAI_KCB_CN'].astype(int))\n",
    "frame\n",
    "# -------------------------- Kết thúc đối mã loại khám, chữa bệnh -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bcf232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Nhóm đổi mã bệnh -----------------------------\n",
    "folder_excel = r\"C:\\Users\\PC\\Desktop\\DOI\"\n",
    "# Tên file excel cần xử lý\n",
    "FileName_Excel = \"DOI_MA_BENH.xlsx\"\n",
    "result = pd.read_excel(folder_excel + \"\\\\\" + FileName_Excel)\n",
    "result\n",
    "# Thay đổi dữ liệu danh sách từ 1 danh sách khác cho trước.\n",
    "\n",
    "value_map = result.set_index('KEY')['MA_BENH'].to_dict()\n",
    "print(\"Số lượt chuyển mã bệnh : \" + str(result.shape[0]))\n",
    "frame['MA_BENH_C7'] = frame['KEY'].map(value_map).fillna(frame['MA_BENH_C7'])\n",
    "frame\n",
    "# -------------------------- Kết thúc đối mã bệnh -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Nhóm điều chỉnh lượt do tách lượt -----------------------------\n",
    "folder_excel = r\"C:\\Users\\PC\\Desktop\\DOI\"\n",
    "# Tên file excel cần xử lý\n",
    "FileName_Excel = \"GHEP_LUOT.xlsx\"\n",
    "result = pd.read_excel(folder_excel + \"\\\\\" + FileName_Excel)\n",
    "result\n",
    "# Thay đổi dữ liệu danh sách từ 1 danh sách khác cho trước.\n",
    "merged_df = frame.merge(result, on='KEY', how='left')\n",
    "print(\"Số lượt ghép do tách lượt : \" + str(merged_df['TACH_LUOT'].notna().sum()))\n",
    "# Set the 'Value' to 0 for the matching keys in main_df\n",
    "frame.loc[merged_df['TACH_LUOT'].notna(), 'TINH_LUOT'] = 0\n",
    "frame\n",
    "# -------------------------- Kết thúc điều chỉnh lượt do tách lượt -------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
